{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import folium\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.distance import geodesic\n",
    "from typing import List, Dict, Tuple, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Global performance def #######\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The purpose of this code is to define a decorator function called measure_time that \n",
    "can be used to measure the execution time of other functions. By applying this decorator \n",
    "to a function, you can easily track how long it takes to execute.\n",
    "\n",
    "When the measure_time decorator is applied to a function, it wraps the original \n",
    "function with a wrapper function. The wrapper function checks if the measurement is enabled. \n",
    "If it is, the wrapper function records the start time, calls the original function, \n",
    "records the end time, calculates the execution time, and prints the results. \n",
    "Finally, it returns the result of the original function.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def measure_time(func):\n",
    "    # Get the enabled value outside the wrapper\n",
    "    enabled = measure_time.enabled  \n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # ensure we're using the latest settings\n",
    "        enabled = measure_time.enabled  \n",
    "        if enabled:\n",
    "            \n",
    "            start_time = time.time()  \n",
    "            # Call the original function with the provided arguments\n",
    "            result = func(*args, **kwargs)  \n",
    "            end_time = time.time()  \n",
    "            execution_time = end_time - start_time \n",
    "            \n",
    "            print(f\" the Function: {func.__name__} took: {execution_time} seconds\") \n",
    "            return result  # Return the result of the decorated function\n",
    "        else:\n",
    "            # If the decorator is disabled, simply call the original function\n",
    "            return func(*args, **kwargs)  \n",
    "\n",
    "    # Return the wrapper function only if enabled, else return the original function\n",
    "    return wrapper if enabled else func\n",
    "\n",
    "\n",
    "####### ####### ####### ####### #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39090aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Global ploting system #######\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The purpose of this code is to define a function called plot_cities that creates a map \n",
    "with markers and lines to visualize city data. The function takes \n",
    "two parameters: city_data, which contains the information about the cities to be \n",
    "plotted, and bound (optional), which specifies the order of cities to be plotted.\n",
    "\n",
    "The plot_cities function contains several helper functions:\n",
    "\n",
    "* arrange_cities_nearest: This function arranges the cities in city_data in the order \n",
    "specified by path. It sorts the cities based on their index in the path list, ensuring \n",
    "that the cities are plotted in the desired order.\n",
    "\n",
    "* create_map_center: This function extracts the coordinates of the first city in \n",
    "city_data and returns them as the center of the map.\n",
    "\n",
    "* create_custom_icon_style: This function defines a custom icon style for the markers \n",
    "on the map. It sets the background color, text color, border radius, padding, font weight, \n",
    "and font size.\n",
    "\n",
    "* add_marker_with_icon: This function adds a marker with a custom icon to the map. \n",
    "It takes the coordinates, name, icon style, and index as parameters and creates a marker \n",
    "with a numbered icon at the specified coordinates.\n",
    "\n",
    "* draw_line_between_cities: This function draws a line between two cities on the map. \n",
    "It takes the coordinates of the current city, the coordinates of the next city, the names \n",
    "of both cities, and the index as parameters. It creates a polyline connecting the two cities with \n",
    "a tooltip indicating the route number and the city names.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "color = [\"Green\", \"Blue\", \"Yellow\", \"Orange\", \"Purple\", \"Pink\", \"Brown\", \"Gray\", \"Black\", \"White\"]\n",
    "\n",
    "def plot_cities(city_data, bound=None, color='blue', map_obj=None):\n",
    "    \n",
    "    def arrange_cities_nearest(city_data, path):\n",
    "        city_names = city_data[:, -1]\n",
    "        sorted_indices = np.argsort([path.index(city) for city in city_names])\n",
    "        sorted_city_data = city_data[sorted_indices]\n",
    "        return np.vstack((sorted_city_data, sorted_city_data[0]))\n",
    "\n",
    "    def create_map_center():\n",
    "        return [float(city_data[0][2]), float(city_data[0][3])]\n",
    "\n",
    "    def create_custom_icon_style():\n",
    "        return \"\"\"\n",
    "            background-color: #ff5959;\n",
    "            color: #ffffff;\n",
    "            border-radius: 100%;\n",
    "            padding: 20%;\n",
    "            text-align: center;\n",
    "            font-weight: bold;\n",
    "            font-size: auto;\n",
    "        \"\"\"\n",
    "\n",
    "    def add_marker_with_icon(coords, name, icon_style, i):\n",
    "        folium.Marker(\n",
    "            coords,\n",
    "            popup=name,\n",
    "            icon=folium.DivIcon(\n",
    "                icon_size=(24, 24),\n",
    "                icon_anchor=(12, 12),\n",
    "                html='<div style=\"{}\">{}</div>'.format(icon_style, i + 1)\n",
    "            )\n",
    "        ).add_to(map_obj)\n",
    "\n",
    "    def draw_line_between_cities(coords, next_coords, name, next_city, i):\n",
    "        folium.PolyLine(\n",
    "            [coords, next_coords],\n",
    "            color=color,\n",
    "            weight=2.5,\n",
    "            opacity=1.0,\n",
    "            tooltip='Route {}: {} -> {}'.format(i + 1, name, next_city[4])\n",
    "        ).add_to(map_obj)\n",
    "\n",
    "    # Create a map if not provided\n",
    "    if map_obj is None:\n",
    "        map_center = create_map_center()\n",
    "        map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "    if bound:\n",
    "        city_data = arrange_cities_nearest(city_data, bound)\n",
    "        # Iterate over the city data and plot markers and lines\n",
    "        for i in range(len(city_data) - 1):\n",
    "            city = city_data[i]\n",
    "            coords = [float(city[2]), float(city[3])]\n",
    "            name = city[4]\n",
    "\n",
    "            icon_style = create_custom_icon_style()\n",
    "\n",
    "            add_marker_with_icon(coords, name, icon_style, i)\n",
    "\n",
    "            next_city = city_data[i + 1]\n",
    "            next_coords = [float(next_city[2]), float(next_city[3])]\n",
    "\n",
    "            draw_line_between_cities(coords, next_coords, name, next_city, i)\n",
    "    else:\n",
    "        # Iterate over the city data and create a folium marker for each city\n",
    "        for city in city_data:\n",
    "            folium.Marker(\n",
    "                location=[float(city[2]), float(city[3])],\n",
    "                popup=city[4]\n",
    "            ).add_to(map_obj)\n",
    "\n",
    "    # Display the map\n",
    "    return map_obj\n",
    "\n",
    "####### ####### ####### ####### #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac586cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Global notebook configs #######\n",
    "\n",
    "# Toggle for enabling/disabling the \n",
    "# decorator\n",
    "measure_time.enabled = True \n",
    "if measure_time.enabled:\n",
    "    print(\"* measure_time is enabled \")\n",
    "\n",
    "# specify the folder path and files name \n",
    "dataset_file_path = os.path.join('../datasets', 'cities.csv')\n",
    "print(f\"* the selected dataset is located at: {dataset_file_path}\")\n",
    "\n",
    "# select the nb of cities you want from the dataset\n",
    "np_of_cities = 200\n",
    "print(f\"* {np_of_cities} will be used from the dataset\")\n",
    "\n",
    "# select the number of truck you wish to divide the workload\n",
    "truck_nb = 5\n",
    "print(f\"* {truck_nb} will be used to deliver the goods\")\n",
    "\n",
    "# choose an average speed that suit your needs (here 51.3 km/h)\n",
    "average_speed = 51.3\n",
    "print(f\"* the average speed is : {average_speed} km/h\")\n",
    "\n",
    "# tabu related conf \n",
    "num_iterations = 100\n",
    "tabu_list_size = 100\n",
    "print(f\"* the tabu list size is : {tabu_list_size} and it will iterate {num_iterations} times\")\n",
    "\n",
    "# multistart related conf\n",
    "num_starts = 10\n",
    "print(f\"* multistart factor : {num_starts}\")\n",
    "\n",
    "####### ####### ####### ####### #######"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448bb767",
   "metadata": {},
   "source": [
    "# City Generator \n",
    "\n",
    "this part contains the folowing logic: we first retrieve data from a dataset and later construct a sample from it that contain the cities name, the ZIP Code, the population count and longitude|latitude "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd191414",
   "metadata": {},
   "source": [
    "<u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def read_csv_to_tuple(filename: str):\n",
    "    with open(filename, \"r\", encoding='ISO-8859-1') as fh:  # Open the file in read mode\n",
    "        # Create a CSV reader object with delimiter ';'\n",
    "        reader = csv.reader(fh, delimiter=';')  \n",
    "        # Skip the header row\n",
    "        next(reader, None)  \n",
    "        # Convert the remaining rows to a tuple\n",
    "        cities = tuple(reader)  \n",
    "    return cities  # Return the tuple\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def sample_N_from_tuple(cities: tuple, size: int = None):\n",
    "    totalRows = len(cities)\n",
    "    # If size is not specified or greater than totalRows Return \n",
    "    # an empty tuple\n",
    "    if size is None or size > totalRows:  \n",
    "        return ()\n",
    "    # Return a random sample of 'size' elements from the tuple\n",
    "    return random.sample(cities, size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b16161",
   "metadata": {},
   "outputs": [],
   "source": [
    "citiesTuple = read_csv_to_tuple(dataset_file_path)\n",
    "citiesSample = sample_N_from_tuple(citiesTuple, np_of_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b172458",
   "metadata": {},
   "source": [
    "<u>optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dda566",
   "metadata": {},
   "source": [
    "- Reads the CSV file using the pandas library's read_csv function.\n",
    "    - Efficient CSV reading: The optimized version uses pandas' read_csv function, which is highly optimized for reading CSV files. It takes advantage of optimized file parsing algorithms and efficient memory management, resulting in faster file reading compared to the line-by-line reading in the non-optimized version.\n",
    "\n",
    "- Converts the DataFrame to a tuple of lists and then to a tuple.\n",
    "    - In the non-optimized version, each row from the CSV file is converted to a tuple individually. In the optimized version, pandas converts the entire DataFrame to a tuple of lists in one operation, which is more efficient and faster.\n",
    "    \n",
    "- Uses pandas and NumPy functions for sampling instead of the random.sample function.\n",
    "    - The non-optimized version uses the random.sample function to sample elements from the tuple. In the optimized version, NumPy's random.choice function is used, which is implemented in optimized C code and performs faster random sampling.\n",
    "    - The optimized version uses pandas' iloc function to extract the sampled data based on the selected indices. This indexing operation is optimized in pandas and provides faster access to the desired rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def read_csv_to_tuple(filename: str):\n",
    "    # Read the CSV file using pandas\n",
    "    df = pd.read_csv(filename, delimiter=';', encoding='ISO-8859-1')\n",
    "    # Convert the DataFrame to a tuple of lists and then to a tuple\n",
    "    cities = tuple(df.values.tolist())  \n",
    "    return cities\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def sample_N_from_tuple(cities: tuple, size: int = None):\n",
    "    # Create a DataFrame from the tuple of lists\n",
    "    df = pd.DataFrame(list(cities))\n",
    "    # Get the total number of rows in the DataFrame\n",
    "    totalRows = len(df)\n",
    "    \n",
    "    # If size is not specified or greater than totalRows\n",
    "    # Return an empty tuple\n",
    "    if size is None or size > totalRows:  \n",
    "        return ()\n",
    "    \n",
    "    # Randomly select 'size' indices without replacement\n",
    "    indices = np.random.choice(totalRows, size, replace=False)\n",
    "    # Extract the sampled data based on the selected indices\n",
    "    sampled_data = df.iloc[indices].values.tolist()  \n",
    "    # Return the sampled data as a NumPy array\n",
    "    return np.array(sampled_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "citiesTuple = read_csv_to_tuple(dataset_file_path)\n",
    "citiesSample = sample_N_from_tuple(citiesTuple, np_of_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee751f2d",
   "metadata": {},
   "source": [
    "<u>the actual output of the city generator section</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable performance profiling for this section \n",
    "measure_time.enabled = False\n",
    "\n",
    "citiesTuple = read_csv_to_tuple(dataset_file_path)\n",
    "citiesSample = sample_N_from_tuple(citiesTuple, np_of_cities)\n",
    "\n",
    "# display the map with the selected cities\n",
    "plot_cities(citiesSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a883824",
   "metadata": {},
   "source": [
    "# location generator \n",
    "The purpose of this staged is to generate a series of city names along with their respective longitude and latitude coordinates. It achieves this by extracting the relevant information from a given list of city data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable performance profiling for this section \n",
    "measure_time.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b915d1",
   "metadata": {},
   "source": [
    "<u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20201119",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def create_location_generator(citiesSample: List[List[str]]) -> Dict[str, Tuple[float, float]]:\n",
    "    # Create an empty dictionary to store the location data\n",
    "    tmp = {}  \n",
    "    \n",
    "    for city in citiesSample:  # Iterate over each city in citiesSample\n",
    "        city_name = city[4]  # Get the city name from the city data\n",
    "        longitude = float(city[3])  # Get the longitude from the city data and convert it to float\n",
    "        latitude = float(city[2])  # Get the latitude from the city data and convert it to float\n",
    "        tmp[city_name] = (longitude, latitude)  # Store the longitude and latitude as a tuple in the dictionary\n",
    "    \n",
    "    # Return the dictionary containing the location data\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75486816",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = create_location_generator(citiesSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fec83b",
   "metadata": {},
   "source": [
    "<u>optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeda1e0",
   "metadata": {},
   "source": [
    "- Uses NumPy array indexing to extract city names, longitudes, and latitudes from the citiesSample list in one operation.\n",
    "    - The optimized version leverages NumPy's array indexing and vectorized operations to extract the necessary data from the citiesSample list. This allows for faster and more efficient data extraction compared to the iterative approach in the non-optimized version.\n",
    "- Converts the longitudes and latitudes to float using NumPy's astype function.\n",
    "    - In the non-optimized version, the conversion to float is performed individually for each longitude and latitude. In the optimized version, NumPy's astype function is applied to the entire arrays of longitudes and latitudes in one operation. This bulk conversion is more efficient and faster.\n",
    "- Utilizes the zip function and generator syntax (yield from) to create a generator that yields tuples of city names and corresponding longitude-latitude pairs.\n",
    "    - The optimized version uses a generator and the yield from syntax to produce the desired output. Generators provide a memory-efficient way to produce values on-the-fly, as opposed to constructing and returning a complete dictionary in the non-optimized version. This can improve performance, especially when dealing with large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def create_location_generator(citiesSample: List[List[str]]) -> Generator[Tuple[str, Tuple[float, float]], None, None]:\n",
    "    # Extract city names from citiesSample using NumPy array indexing\n",
    "    city_names = np.array(citiesSample)[:, 4]\n",
    "    # Extract longitudes and convert them to float using NumPy array indexing\n",
    "    longitudes = np.array(citiesSample)[:, 3].astype(float)\n",
    "    # Extract latitudes and convert them to float using NumPy array indexing\n",
    "    latitudes = np.array(citiesSample)[:, 2].astype(float)\n",
    "\n",
    "    yield from zip(city_names, zip(longitudes, latitudes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = create_location_generator(citiesSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4214bd",
   "metadata": {},
   "source": [
    "<u>the actual output of the location generator section</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd29f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable performance profiling for this section \n",
    "measure_time.enabled = False\n",
    "\n",
    "for city_name, coordinates in create_location_generator(citiesSample):\n",
    "    print(f'{city_name}: {coordinates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c466be",
   "metadata": {},
   "source": [
    "# time matrix generator\n",
    "\n",
    "this part calculate a time matrix for a set of cities based on their geographic coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable performance profiling for this section \n",
    "measure_time.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4d23f",
   "metadata": {},
   "source": [
    "<u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e64801",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def calculate_time_matrix(generator) -> Dict[str, Dict[str, float]]:\n",
    "    time_matrix = {}  # Create an empty dictionary to store the time matrix\n",
    "    city_coords = []  # Create an empty list to store city names and coordinates\n",
    "    \n",
    "    # Iterate over each city name and coordinates from the generator and \n",
    "    # append the city name and coordinates as a tuple to city_coords\n",
    "    for city_name, coordinates in generator:\n",
    "        city_coords.append((city_name, coordinates)) \n",
    "    \n",
    "    # Iterate over the city name and coordinates using enumerate\n",
    "    for i, (city1, coords1) in enumerate(city_coords):\n",
    "        \n",
    "        # Create an empty dictionary for each city in the time matrix\n",
    "        time_matrix[city1] = {}\n",
    "        \n",
    "        # Iterate over the city name and coordinates again\n",
    "        for j, (city2, coords2) in enumerate(city_coords):  \n",
    "            if i == j:\n",
    "                # Set the time between a city and itself to 0.0\n",
    "                time_matrix[city1][city2] = 0.0 \n",
    "            else:\n",
    "                # Calculate the geodesic distance between two coordinates\n",
    "                distance = geodesic(coords1, coords2).kilometers\n",
    "                # Store the time in the time matrix\n",
    "                time_matrix[city1][city2] = distance / average_speed \n",
    "    \n",
    "    return time_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed715e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_matrix = calculate_time_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f605f5",
   "metadata": {},
   "source": [
    "<u>optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253673c0",
   "metadata": {},
   "source": [
    "- The optimized version directly stores the city coordinates in a dictionary (city_coords), eliminating the need for additional data structures like the city_coords list in the non-optimized version. This reduces memory usage and unnecessary operations, resulting in improved performance.\n",
    "- The optimized version utilizes NumPy's vectorized operations to calculate times between pairs of coordinates. By converting the coordinates to a NumPy array and using broadcasting, the calculations can be performed efficiently in parallel, leading to significant speed improvements.\n",
    "- Instead of constructing an empty dictionary for each city, the optimized version creates a square matrix (times) with zeros to store the time values. This allows for efficient indexing and updating of the times using NumPy operations.\n",
    "- The optimized version converts the times matrix to a pandas DataFrame, which provides efficient indexing capabilities and convenient conversion to a dictionary. This avoids nested loops and dictionary updates in the non-optimized version, resulting in improved performance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "359ccf35",
   "metadata": {},
   "source": [
    "/!\\ patched but no longer faster than the non-opti one\n",
    "@measure_time\n",
    "def calculate_time_matrix(generator) -> Dict[str, Dict[str, float]]:\n",
    "    city_coords = {}  # Create an empty dictionary to store city coordinates\n",
    "\n",
    "    # Iterate over city name and coordinates from the generator and \n",
    "    # Store the coordinates in the city_coords dictionary\n",
    "    for city_name, coordinates in generator:\n",
    "        city_coords[city_name] = coordinates\n",
    "\n",
    "    cities = list(city_coords.keys())  # Get a list of city names\n",
    "\n",
    "    coords = np.array(list(city_coords.values()))  # Convert coordinates to a NumPy array\n",
    "    num_cities = len(cities)\n",
    "\n",
    "    # Calculate pairwise times using cdist and geodesic\n",
    "    times = cdist(coords, coords, lambda u, v: geodesic(u, v).kilometers)\n",
    "\n",
    "    # Create a DataFrame from the times array for easier indexing\n",
    "    df_times = pd.DataFrame(times, index=cities, columns=cities)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    time_matrix = df_times.to_dict()\n",
    "\n",
    "    return time_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54dcae67",
   "metadata": {},
   "source": [
    "time_matrix = calculate_time_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb7ef2",
   "metadata": {},
   "source": [
    "<u>the actual output of the time matrix generator section</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329b04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# disable performance profiling for this section \n",
    "measure_time.enabled = False\n",
    "\n",
    "calculate_time_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e87eb",
   "metadata": {},
   "source": [
    "# tabu algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_the_output(best_time, best_route): \n",
    "    print(f\"Best time: {best_time} h\")\n",
    "    print(\"Best Route:\", ' -> '.join(best_route))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7905b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search(time_matrix, num_iterations, tabu_list_size, start_town=None, progress_enable = True):\n",
    "    # Initialize the tabu list as an empty set\n",
    "    tabu_list = set()\n",
    "    # Generate an initial random solution\n",
    "    if start_town is None:\n",
    "        best_route = list(time_matrix.keys())\n",
    "        np.random.shuffle(best_route)\n",
    "    else:\n",
    "        best_route = list(time_matrix.keys())\n",
    "        best_route.remove(start_town)\n",
    "        best_route.insert(0, start_town)\n",
    "    best_time = calculate_total_time(best_route, time_matrix)\n",
    "\n",
    "    # Create a progress bar using tqdm\n",
    "    if progress_enable: \n",
    "        progress_bar = tqdm(\n",
    "            total=num_iterations, \n",
    "            desc=\"Tabu Search\", \n",
    "            unit=\"iteration\", \n",
    "        )\n",
    "\n",
    "    # Start the iterations\n",
    "    for _ in range(num_iterations):\n",
    "        # Find the best neighboring solution\n",
    "        neighbors = generate_neighbors(best_route, tabu_list)\n",
    "        \n",
    "        # [hack] Check if neighbors list is empty \n",
    "        if not neighbors:\n",
    "            if progress_enable: \n",
    "                progress_bar.update(num_iterations - progress_bar.n)  # Force progress to 100%\n",
    "            continue\n",
    "        \n",
    "        best_neighbor = min(neighbors, key=lambda x: calculate_total_time(x, time_matrix))\n",
    "\n",
    "        # Update the best solution if the neighbor is an improvement\n",
    "        neighbor_time = calculate_total_time(best_neighbor, time_matrix)\n",
    "        if neighbor_time < best_time:\n",
    "            best_route = best_neighbor\n",
    "            best_time = neighbor_time\n",
    "\n",
    "        # Add the best neighbor to the tabu list\n",
    "        tabu_list.add(tuple(best_neighbor))\n",
    "        # Remove the oldest solution from the tabu list if it exceeds the tabu list size\n",
    "        if len(tabu_list) > tabu_list_size:\n",
    "            tabu_list.remove(next(iter(tabu_list)))\n",
    "\n",
    "        # Update the progress bar\n",
    "        if progress_enable: \n",
    "            progress_bar.update(1)\n",
    "\n",
    "    # Append the first town to the best route to complete the cycle\n",
    "    best_route.append(best_route[0])\n",
    "    best_time += time_matrix[best_route[-2]][best_route[0]]\n",
    "\n",
    "    # Close the progress bar\n",
    "    if progress_enable: \n",
    "        progress_bar.close()\n",
    "\n",
    "    return best_route, best_time\n",
    "\n",
    "\n",
    "def calculate_total_time(route, time_matrix):\n",
    "    total_time = 0.0\n",
    "    num_cities = len(route)\n",
    "    for i in range(num_cities - 1):\n",
    "        current_city = route[i]\n",
    "        next_city = route[i + 1]\n",
    "        total_time += time_matrix[current_city][next_city]\n",
    "    return total_time\n",
    "\n",
    "\n",
    "def generate_neighbors(route, tabu_list):\n",
    "    neighbors = []\n",
    "    num_cities = len(route)\n",
    "    for i in range(1, num_cities):\n",
    "        for j in range(i + 1, num_cities):\n",
    "            neighbor = route[:i] + route[i:j][::-1] + route[j:]\n",
    "            if tuple(neighbor) not in tabu_list:\n",
    "                neighbors.append(neighbor)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_matrix = calculate_time_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")\n",
    "\n",
    "best_route, best_time = tabu_search(time_matrix, num_iterations, tabu_list_size)\n",
    "\n",
    "pprint_the_output(best_time, best_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec351ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cities(citiesSample, best_route)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2742b34",
   "metadata": {},
   "source": [
    "# tabu algorithm with traffic constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eff39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "The traffic matrix generator applies a random factor to the times \n",
    "in order to simulate the increased time it would take to travel from \n",
    "city A to city B due to traffic conditions. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def generate_traffic_matrix(time_matrix):\n",
    "    traffic_matrix = {}\n",
    "\n",
    "    for city_a, times in time_matrix.items():\n",
    "        traffic_matrix[city_a] = {}\n",
    "\n",
    "        for city_b, time in times.items():\n",
    "            if city_a == city_b:\n",
    "                traffic_matrix[city_a][city_b] = 1.0  # Assuming no traffic within the same city\n",
    "            else:\n",
    "                traffic_matrix[city_a][city_b] = np.random.uniform(1.0, 1.5) * time\n",
    "    \n",
    "    return traffic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad248928",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_matrix = calculate_time_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")\n",
    "\n",
    "traffic_matrix = generate_traffic_matrix(time_matrix)\n",
    "\n",
    "best_route, best_time = tabu_search(traffic_matrix, num_iterations, tabu_list_size)\n",
    "\n",
    "pprint_the_output(best_time, best_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cities(citiesSample, best_route)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0e3b0",
   "metadata": {},
   "source": [
    "# tabu algorithm with nb truck constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_trucks(time_matrix, num_trucks):\n",
    "    # Convert the time matrix to a numpy array\n",
    "    towns = list(time_matrix.keys())\n",
    "    time_array = np.array([[time_matrix[town1][town2] for town2 in towns] for town1 in towns])\n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_trucks, random_state=0, n_init=10).fit(time_array)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # Find the index of the first town in the time matrix\n",
    "    first_town_index = towns.index(towns[0])\n",
    "    \n",
    "    # Create time matrices for each truck\n",
    "    trucks = []\n",
    "    for i in range(num_trucks):\n",
    "        # Filter towns based on the label or if it's the first town\n",
    "        truck_towns = [towns[j] for j in range(len(towns)) if labels[j] == i or j == first_town_index]\n",
    "        truck_time_matrix = {town: {truck_town: time_matrix[town][truck_town] for truck_town in truck_towns} for town in truck_towns}\n",
    "        trucks.append(truck_time_matrix)\n",
    "    \n",
    "    return trucks\n",
    "\n",
    "def filter_cities_by_truck(citiesSample, truck):\n",
    "    town_list = list(truck.keys())\n",
    "    filtered_cities = [city for city in citiesSample if city[4] in town_list]\n",
    "    return np.array(filtered_cities)\n",
    "\n",
    "\n",
    "def optimize_trucks(trucks, map_obj, use_traffic_matrix=False):\n",
    "    for i, truck in enumerate(trucks):\n",
    "        if use_traffic_matrix:\n",
    "            truck = generate_traffic_matrix(truck)\n",
    "        best_route, best_time = tabu_search(truck, num_iterations, tabu_list_size, start_town=next(iter(truck)))\n",
    "            \n",
    "        print(f\"The truck n: {i}\")\n",
    "        pprint_the_output(best_time, best_route)\n",
    "        plot_cities(filter_cities_by_truck(citiesSample, truck), best_route, map_obj=map_obj, color=color[i])\n",
    "    \n",
    "    return map_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks = split_into_trucks(time_matrix, truck_nb)\n",
    "\n",
    "map_center = [float(citiesSample[0][2]), float(citiesSample[0][3])]\n",
    "map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "\n",
    "optimize_trucks(trucks, map_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dccf35",
   "metadata": {},
   "source": [
    "# tabu algorithm with nb truck and  traffic constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks = split_into_trucks(time_matrix, truck_nb)\n",
    "\n",
    "map_center = [float(citiesSample[0][2]), float(citiesSample[0][3])]\n",
    "map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "optimize_trucks(trucks, map_obj, use_traffic_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6efc0",
   "metadata": {},
   "source": [
    "# dummy multi-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359efbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def multi_start_optimization(time_matrix, truck_nb, map_obj, num_starts, use_traffic_matrix=False):\n",
    "    best_routes = []\n",
    "    best_times = []\n",
    "    total_times = []\n",
    "    trucks_list = []\n",
    "\n",
    "    for i in tqdm(range(num_starts), desc=\"multistart\"):\n",
    "        time_matrix_shuffled = list(time_matrix.items())\n",
    "        np.random.shuffle(time_matrix_shuffled)\n",
    "        time_matrix_shuffled = dict(time_matrix_shuffled)\n",
    "        \n",
    "        trucks = split_into_trucks(time_matrix_shuffled, truck_nb)\n",
    "        trucks_list.append(trucks)\n",
    "        \n",
    "        start_routes = []\n",
    "        start_times = []\n",
    "\n",
    "        for i, truck in enumerate(trucks):\n",
    "            if use_traffic_matrix:\n",
    "                truck = generate_traffic_matrix(truck)\n",
    "            route, time = tabu_search(truck, num_iterations=100, tabu_list_size=100, start_town=next(iter(truck)), progress_enable=False)\n",
    "\n",
    "            start_routes.append(route)\n",
    "            start_times.append(time)\n",
    "\n",
    "        best_routes.append(start_routes)\n",
    "        best_times.append(start_times)\n",
    "        total_time = sum(start_times)\n",
    "        total_times.append(total_time)\n",
    "\n",
    "    sorted_starts = sorted(range(num_starts), key=lambda k: total_times[k], reverse=True)\n",
    "        \n",
    "    for i, truck in enumerate(trucks_list[sorted_starts[-1]]):\n",
    "        route = [lst for lst in best_routes[sorted_starts[-1]] if list(truck.keys())[1] in lst][0]\n",
    "        plot_cities(filter_cities_by_truck(citiesSample, truck), route, map_obj=map_obj, color=color[i])\n",
    "    \n",
    "    print(f\"the best route is : {best_routes[sorted_starts[-1]]} \\n and it will take {total_times[sorted_starts[-1]]} h\")\n",
    "    return map_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e25c4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map_center = [float(citiesSample[0][2]), float(citiesSample[0][3])]\n",
    "map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "multi_start_optimization(time_matrix, truck_nb, map_obj, num_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed856f3",
   "metadata": {},
   "source": [
    "# multistart with //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b379261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def multi_start_optimization(time_matrix, truck_nb, map_obj, num_starts, use_traffic_matrix=False, max_threads=4):\n",
    "    best_routes = []\n",
    "    best_times = []\n",
    "    total_times = []\n",
    "    trucks_list = []\n",
    "\n",
    "    def optimize_start(start_index):\n",
    "        time_matrix_shuffled = list(time_matrix.items())\n",
    "        np.random.shuffle(time_matrix_shuffled)\n",
    "        time_matrix_shuffled = dict(time_matrix_shuffled)\n",
    "\n",
    "        trucks = split_into_trucks(time_matrix_shuffled, truck_nb)\n",
    "        trucks_list.append(trucks)\n",
    "\n",
    "        start_routes = []\n",
    "        start_times = []\n",
    "\n",
    "        for i, truck in enumerate(trucks):\n",
    "            if use_traffic_matrix:\n",
    "                truck = generate_traffic_matrix(truck)\n",
    "\n",
    "            route, time = tabu_search(truck, num_iterations=100, tabu_list_size=100, start_town=next(iter(truck)), progress_enable=False)\n",
    "\n",
    "            start_routes.append(route)\n",
    "            start_times.append(time)\n",
    "            \n",
    "            progress_bar.update(1)  # Increment the common progress bar\n",
    "\n",
    "        best_routes.append(start_routes)\n",
    "        best_times.append(start_times)\n",
    "        total_time = sum(start_times)\n",
    "        total_times.append(total_time)\n",
    "\n",
    "    # Create a single common progress bar\n",
    "    progress_bar = tqdm(total=num_starts * truck_nb, desc=\"parallelised multistart\", position=0)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(optimize_start, i) for i in range(num_starts)]\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "    progress_bar.close()  # Close the common progress bar\n",
    "\n",
    "    sorted_starts = sorted(range(num_starts), key=lambda k: total_times[k], reverse=True)\n",
    "\n",
    "    for i, truck in enumerate(trucks_list[sorted_starts[-1]]):\n",
    "        route = [lst for lst in best_routes[sorted_starts[-1]] if list(truck.keys())[1] in lst][0]\n",
    "        plot_cities(filter_cities_by_truck(citiesSample, truck), route, map_obj=map_obj, color=color[i])\n",
    "\n",
    "    print(f\"The best route is: {best_routes[sorted_starts[-1]]}\\n and it will take {total_times[sorted_starts[-1]]} h\")\n",
    "    return map_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46145109",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = [float(citiesSample[0][2]), float(citiesSample[0][3])]\n",
    "map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "multi_start_optimization(time_matrix, truck_nb, map_obj, num_starts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
