{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import folium\n",
    "import random\n",
    "import pulp \n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic\n",
    "from typing import List, Dict, Tuple, Generator\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c79d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_count= 50 #Nombre de villes de l'algorithme\n",
    "truck_number = 6 #Nombre de camions pour la version avec camions\n",
    "start_time = 480 #Heure de départ en minutes\n",
    "\n",
    "population_size = 500 #Taille de la population de l'algo gén\n",
    "num_generations = 500 #Nombre de génération\n",
    "children_size = 498 #Nombre d'enfants issus des parents précédents\n",
    "mutation_rate = 99 #taux de mutation\n",
    "tournament_size = 20 #Taille du pool de sélection de parents\n",
    "elite_size = 1 #Nombre d'élites issues de la génération précédente en plus du premier\n",
    "num_iteration = 5 #Nombre d'itérations du multistart\n",
    "initial_random_seed = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_to_default_seed():\n",
    "    random.seed(initial_random_seed)\n",
    "    np.random.seed(initial_random_seed)\n",
    "    resetGlobal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e456c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetGlobal():\n",
    "    global globalcity_count,truck_number,start_time,population_size,num_generations,children_size,mutation_rate,tournament_size,elite_size ,num_iteration\n",
    "    city_count= 50 #Nombre de villes de l'algorithme\n",
    "    truck_number = 6 #Nombre de camions pour la version avec camions\n",
    "    start_time = 480 #Heure de départ en minutes\n",
    "\n",
    "    population_size = 500 #Taille de la population de l'algo gén\n",
    "    num_generations = 1600 #Nombre de génération\n",
    "    children_size = 398 #Nombre d'enfants issus des parents précédents\n",
    "    mutation_rate = 99 #taux de mutation\n",
    "    tournament_size = 20 #Taille du pool de sélection de parents\n",
    "    elite_size = 1 #Nombre d'élites issues de la génération précédente en plus du premier\n",
    "    num_iteration = 5 #Nombre d'itérations du multistart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Global performance def #######\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The purpose of this code is to define a decorator function called measure_time that \n",
    "can be used to measure the execution time of other functions. By applying this decorator \n",
    "to a function, you can easily track how long it takes to execute.\n",
    "\n",
    "When the measure_time decorator is applied to a function, it wraps the original \n",
    "function with a wrapper function. The wrapper function checks if the measurement is enabled. \n",
    "If it is, the wrapper function records the start time, calls the original function, \n",
    "records the end time, calculates the execution time, and prints the results. \n",
    "Finally, it returns the result of the original function.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def measure_time(func):\n",
    "    # Get the enabled value outside the wrapper\n",
    "    enabled = measure_time.enabled  \n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # ensure we're using the latest settings\n",
    "        enabled = measure_time.enabled  \n",
    "        if enabled:\n",
    "            \n",
    "            start_time = time.time()  \n",
    "            # Call the original function with the provided arguments\n",
    "            result = func(*args, **kwargs)  \n",
    "            end_time = time.time()  \n",
    "            execution_time = end_time - start_time \n",
    "            \n",
    "            print(f\" the Function: {func.__name__} took: {execution_time} seconds\") \n",
    "            return result  # Return the result of the decorated function\n",
    "        else:\n",
    "            # If the decorator is disabled, simply call the original function\n",
    "            return func(*args, **kwargs)  \n",
    "\n",
    "    # Return the wrapper function only if enabled, else return the original function\n",
    "    return wrapper if enabled else func\n",
    "\n",
    "\n",
    "####### ####### ####### ####### #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39090aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Global ploting system #######\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The purpose of this code is to define a function called plot_cities that creates a map \n",
    "with markers and lines to visualize city data. The function takes \n",
    "two parameters: city_data, which contains the information about the cities to be \n",
    "plotted, and bound (optional), which specifies the order of cities to be plotted.\n",
    "\n",
    "The plot_cities function contains several helper functions:\n",
    "\n",
    "* arrange_cities_nearest: This function arranges the cities in city_data in the order \n",
    "specified by path. It sorts the cities based on their index in the path list, ensuring \n",
    "that the cities are plotted in the desired order.\n",
    "\n",
    "* create_map_center: This function extracts the coordinates of the first city in \n",
    "city_data and returns them as the center of the map.\n",
    "\n",
    "* create_custom_icon_style: This function defines a custom icon style for the markers \n",
    "on the map. It sets the background color, text color, border radius, padding, font weight, \n",
    "and font size.\n",
    "\n",
    "* add_marker_with_icon: This function adds a marker with a custom icon to the map. \n",
    "It takes the coordinates, name, icon style, and index as parameters and creates a marker \n",
    "with a numbered icon at the specified coordinates.\n",
    "\n",
    "* draw_line_between_cities: This function draws a line between two cities on the map. \n",
    "It takes the coordinates of the current city, the coordinates of the next city, the names \n",
    "of both cities, and the index as parameters. It creates a polyline connecting the two cities with \n",
    "a tooltip indicating the route number and the city names.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "color = [\"Green\", \"Blue\", \"Yellow\", \"Orange\", \"Purple\", \"Pink\", \"Brown\", \"Gray\", \"Black\", \"White\",\"Red\"]\n",
    "\n",
    "def plot_cities(city_data, bound=None, color='blue', map_obj=None):\n",
    "    \n",
    "    def arrange_cities_nearest(city_data, path):\n",
    "        city_names = city_data[:, -1]\n",
    "        sorted_indices = np.argsort([path.index(city) for city in city_names])\n",
    "        sorted_city_data = city_data[sorted_indices]\n",
    "        return np.vstack((sorted_city_data, sorted_city_data[0]))\n",
    "\n",
    "    def create_map_center():\n",
    "        return [float(city_data[0][2]), float(city_data[0][3])]\n",
    "\n",
    "    def create_custom_icon_style():\n",
    "        return \"\"\"\n",
    "            background-color: #ff5959;\n",
    "            color: #ffffff;\n",
    "            border-radius: 100%;\n",
    "            padding: 20%;\n",
    "            text-align: center;\n",
    "            font-weight: bold;\n",
    "            font-size: auto;\n",
    "        \"\"\"\n",
    "\n",
    "    def add_marker_with_icon(coords, name, icon_style, i):\n",
    "        folium.Marker(\n",
    "            coords,\n",
    "            popup=name,\n",
    "            icon=folium.DivIcon(\n",
    "                icon_size=(24, 24),\n",
    "                icon_anchor=(12, 12),\n",
    "                html='<div style=\"{}\">{}</div>'.format(icon_style, i + 1)\n",
    "            )\n",
    "        ).add_to(map_obj)\n",
    "\n",
    "    def draw_line_between_cities(coords, next_coords, name, next_city, i):\n",
    "        folium.PolyLine(\n",
    "            [coords, next_coords],\n",
    "            color=color,\n",
    "            weight=2.5,\n",
    "            opacity=1.0,\n",
    "            tooltip='Route {}: {} -> {}'.format(i + 1, name, next_city[4])\n",
    "        ).add_to(map_obj)\n",
    "\n",
    "    # Create a map if not provided\n",
    "    if map_obj is None:\n",
    "        map_center = create_map_center()\n",
    "        map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "    if bound:\n",
    "        city_data = arrange_cities_nearest(city_data, bound)\n",
    "        # Iterate over the city data and plot markers and lines\n",
    "        for i in range(len(city_data) - 1):\n",
    "            city = city_data[i]\n",
    "            coords = [float(city[2]), float(city[3])]\n",
    "            name = city[4]\n",
    "\n",
    "            icon_style = create_custom_icon_style()\n",
    "\n",
    "            add_marker_with_icon(coords, name, icon_style, i)\n",
    "\n",
    "            next_city = city_data[i + 1]\n",
    "            next_coords = [float(next_city[2]), float(next_city[3])]\n",
    "\n",
    "            draw_line_between_cities(coords, next_coords, name, next_city, i)\n",
    "    else:\n",
    "        # Iterate over the city data and create a folium marker for each city\n",
    "        for city in city_data:\n",
    "            folium.Marker(\n",
    "                location=[float(city[2]), float(city[3])],\n",
    "                popup=city[4]\n",
    "            ).add_to(map_obj)\n",
    "\n",
    "    # Display the map\n",
    "    return map_obj\n",
    "\n",
    "####### ####### ####### ####### #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac586cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Global notebook configs #######\n",
    "\n",
    "# Toggle for enabling/disabling the \n",
    "# decorator\n",
    "measure_time.enabled = True \n",
    "if measure_time.enabled:\n",
    "    print(\"* measure_time is enabled \")\n",
    "\n",
    "# specify the folder path and files name \n",
    "dataset_file_path = os.path.join('../datasets', 'cities.csv')\n",
    "print(f\"* the selected dataset is located at: {dataset_file_path}\")\n",
    "\n",
    "####### ####### ####### ####### #######"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448bb767",
   "metadata": {},
   "source": [
    "# City Generator \n",
    "\n",
    "this part contains the folowing logic: we first retrieve data from a dataset and later construct a sample from it that contain the cities name, the ZIP Code, the population count and longitude|latitude "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd191414",
   "metadata": {},
   "source": [
    "<u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def read_csv_to_tuple(filename: str):\n",
    "    with open(filename, \"r\", encoding='ISO-8859-1') as fh:  # Open the file in read mode\n",
    "        # Create a CSV reader object with delimiter ';'\n",
    "        reader = csv.reader(fh, delimiter=';')  \n",
    "        # Skip the header row\n",
    "        next(reader, None)  \n",
    "        # Convert the remaining rows to a tuple\n",
    "        cities = tuple(reader)  \n",
    "    return cities  # Return the tuple\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def sample_N_from_tuple(cities: tuple, size: int = None):\n",
    "    totalRows = len(cities)\n",
    "    # If size is not specified or greater than totalRows Return \n",
    "    # an empty tuple\n",
    "    if size is None or size > totalRows:  \n",
    "        return ()\n",
    "    # Return a random sample of 'size' elements from the tuple\n",
    "    return random.sample(cities, size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b16161",
   "metadata": {},
   "outputs": [],
   "source": [
    "citiesTuple = read_csv_to_tuple(dataset_file_path)\n",
    "citiesSample = sample_N_from_tuple(citiesTuple, city_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b172458",
   "metadata": {},
   "source": [
    "<u>optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dda566",
   "metadata": {},
   "source": [
    "- Reads the CSV file using the pandas library's read_csv function.\n",
    "    - Efficient CSV reading: The optimized version uses pandas' read_csv function, which is highly optimized for reading CSV files. It takes advantage of optimized file parsing algorithms and efficient memory management, resulting in faster file reading compared to the line-by-line reading in the non-optimized version.\n",
    "\n",
    "- Converts the DataFrame to a tuple of lists and then to a tuple.\n",
    "    - In the non-optimized version, each row from the CSV file is converted to a tuple individually. In the optimized version, pandas converts the entire DataFrame to a tuple of lists in one operation, which is more efficient and faster.\n",
    "    \n",
    "- Uses pandas and NumPy functions for sampling instead of the random.sample function.\n",
    "    - The non-optimized version uses the random.sample function to sample elements from the tuple. In the optimized version, NumPy's np.random.choice function is used, which is implemented in optimized C code and performs faster random sampling.\n",
    "    - The optimized version uses pandas' iloc function to extract the sampled data based on the selected indices. This indexing operation is optimized in pandas and provides faster access to the desired rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def read_csv_to_tuple(filename: str):\n",
    "    # Read the CSV file using pandas\n",
    "    df = pd.read_csv(filename, delimiter=';', encoding='ISO-8859-1')\n",
    "    # Convert the DataFrame to a tuple of lists and then to a tuple\n",
    "    cities = tuple(df.values.tolist())  \n",
    "    return cities\n",
    "\n",
    "\n",
    "@measure_time\n",
    "def sample_N_from_tuple(cities: tuple, size: int = None):\n",
    "    # Create a DataFrame from the tuple of lists\n",
    "    df = pd.DataFrame(list(cities))\n",
    "    # Get the total number of rows in the DataFrame\n",
    "    totalRows = len(df)\n",
    "    \n",
    "    # If size is not specified or greater than totalRows\n",
    "    # Return an empty tuple\n",
    "    if size is None or size > totalRows:  \n",
    "        return ()\n",
    "    \n",
    "    # Randomly select 'size' indices without replacement\n",
    "    indices = np.random.choice(totalRows, size, replace=False)\n",
    "    # Extract the sampled data based on the selected indices\n",
    "    sampled_data = df.iloc[indices].values.tolist()  \n",
    "    # Return the sampled data as a NumPy array\n",
    "    return np.array(sampled_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_to_default_seed()\n",
    "\n",
    "citiesTuple = read_csv_to_tuple(dataset_file_path)\n",
    "citiesSample = sample_N_from_tuple(citiesTuple, city_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee751f2d",
   "metadata": {},
   "source": [
    "<u>the actual output of the city generator section</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable performance profiling for this section \n",
    "measure_time.enabled = False\n",
    "reset_to_default_seed()\n",
    "\n",
    "citiesTuple = read_csv_to_tuple(dataset_file_path)\n",
    "citiesSample = sample_N_from_tuple(citiesTuple, city_count)\n",
    "\n",
    "# display the map with the selected cities\n",
    "plot_cities(citiesSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a883824",
   "metadata": {},
   "source": [
    "# location generator \n",
    "The purpose of this staged is to generate a series of city names along with their respective longitude and latitude coordinates. It achieves this by extracting the relevant information from a given list of city data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable performance profiling for this section \n",
    "measure_time.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b915d1",
   "metadata": {},
   "source": [
    "<u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20201119",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def create_location_generator(citiesSample: List[List[str]]) -> Dict[str, Tuple[float, float]]:\n",
    "    # Create an empty dictionary to store the location data\n",
    "    tmp = {}  \n",
    "    \n",
    "    for city in citiesSample:  # Iterate over each city in citiesSample\n",
    "        city_name = city[4]  # Get the city name from the city data\n",
    "        longitude = float(city[3])  # Get the longitude from the city data and convert it to float\n",
    "        latitude = float(city[2])  # Get the latitude from the city data and convert it to float\n",
    "        population = int(city[1]) # Get the population from the city data and convert it to int\n",
    "        tmp[city_name] = (longitude, latitude,population)  # Store the population, longitude and latitude as a tuple in the dictionary\n",
    "    \n",
    "    # Return the dictionary containing the location data\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75486816",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = create_location_generator(citiesSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fec83b",
   "metadata": {},
   "source": [
    "<u>optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeda1e0",
   "metadata": {},
   "source": [
    "- Uses NumPy array indexing to extract city names, longitudes, and latitudes from the citiesSample list in one operation.\n",
    "    - The optimized version leverages NumPy's array indexing and vectorized operations to extract the necessary data from the citiesSample list. This allows for faster and more efficient data extraction compared to the iterative approach in the non-optimized version.\n",
    "- Converts the longitudes and latitudes to float using NumPy's astype function.\n",
    "    - In the non-optimized version, the conversion to float is performed individually for each longitude and latitude. In the optimized version, NumPy's astype function is applied to the entire arrays of longitudes and latitudes in one operation. This bulk conversion is more efficient and faster.\n",
    "- Utilizes the zip function and generator syntax (yield from) to create a generator that yields tuples of city names and corresponding longitude-latitude pairs.\n",
    "    - The optimized version uses a generator and the yield from syntax to produce the desired output. Generators provide a memory-efficient way to produce values on-the-fly, as opposed to constructing and returning a complete dictionary in the non-optimized version. This can improve performance, especially when dealing with large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def create_location_generator(citiesSample: List[List[str]]) -> Generator[Tuple[str, Tuple[float, float]], None, None]:\n",
    "    # Extract city names from citiesSample using NumPy array indexing\n",
    "    city_names = np.array(citiesSample)[:, 4]\n",
    "    # Extract longitudes and convert them to float using NumPy array indexing\n",
    "    longitudes = np.array(citiesSample)[:, 3].astype(float)\n",
    "    # Extract latitudes and convert them to float using NumPy array indexing\n",
    "    latitudes = np.array(citiesSample)[:, 2].astype(float)\n",
    "    # Extract population and convert them to int using NumPy array indexing\n",
    "    population = np.array(citiesSample)[:, 1].astype(int)\n",
    "\n",
    "    yield from zip(city_names, zip(longitudes, latitudes,population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = create_location_generator(citiesSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4214bd",
   "metadata": {},
   "source": [
    "<u>the actual output of the location generator section</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable performance profiling for this section \n",
    "measure_time.enabled = False\n",
    "\n",
    "for city_name, coordinates in create_location_generator(citiesSample):\n",
    "    print(f'{city_name}: {coordinates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c466be",
   "metadata": {},
   "source": [
    "# distance matrix generator\n",
    "\n",
    "this part calculate a distance matrix for a set of cities based on their geographic coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable performance profiling for this section \n",
    "measure_time.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4d23f",
   "metadata": {},
   "source": [
    "<u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e64801",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def calculate_distance_matrix(generator) -> Dict[str, Dict[str, float]]:\n",
    "    distance_matrix = {}  # Create an empty dictionary to store the distance matrix\n",
    "    city_coords = []  # Create an empty list to store city names and coordinates\n",
    "    \n",
    "    # Iterate over each city name and coordinates from the generator and \n",
    "    # append the city name and coordinates as a tuple to city_coords\n",
    "    for city_name, coordinates in generator:\n",
    "        city_coords.append((city_name, tuple([coordinates[1],coordinates[0],0]))) \n",
    "    # Iterate over the city name and coordinates using enumerate\n",
    "    for i, (city1, coords1) in enumerate(city_coords):\n",
    "        \n",
    "        # Create an empty dictionary for each city in the distance matrix\n",
    "        distance_matrix[city1] = {}\n",
    "        \n",
    "        # Iterate over the city name and coordinates again\n",
    "        for j, (city2, coords2) in enumerate(city_coords):  \n",
    "            if i == j:\n",
    "                # Set the distance between a city and itself to 0.0\n",
    "                distance_matrix[city1][city2] = 0.0 \n",
    "            else:\n",
    "                # Calculate the geodesic distance between two coordinates\n",
    "                distance = geodesic(coords1, coords2).kilometers\n",
    "                # Store the distance in the distance matrix\n",
    "                distance_matrix[city1][city2] = distance / 51.3\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed715e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = calculate_distance_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f605f5",
   "metadata": {},
   "source": [
    "<u>optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253673c0",
   "metadata": {},
   "source": [
    "- The optimized version directly stores the city coordinates in a dictionary (city_coords), eliminating the need for additional data structures like the city_coords list in the non-optimized version. This reduces memory usage and unnecessary operations, resulting in improved performance.\n",
    "- The optimized version utilizes NumPy's vectorized operations to calculate distances between pairs of coordinates. By converting the coordinates to a NumPy array and using broadcasting, the calculations can be performed efficiently in parallel, leading to significant speed improvements.\n",
    "- Instead of constructing an empty dictionary for each city, the optimized version creates a square matrix (distances) with zeros to store the distance values. This allows for efficient indexing and updating of the distances using NumPy operations.\n",
    "- The optimized version converts the distances matrix to a pandas DataFrame, which provides efficient indexing capabilities and convenient conversion to a dictionary. This avoids nested loops and dictionary updates in the non-optimized version, resulting in improved performance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "51e46a94",
   "metadata": {},
   "source": [
    "/!\\ patched but no longer faster than the non-opti one\n",
    "@measure_time\n",
    "def calculate_distance_matrix(generator) -> Dict[str, Dict[str, float]]:\n",
    "    city_coords = {}  # Create an empty dictionary to store city coordinates\n",
    "\n",
    "    # Iterate over city name and coordinates from the generator and \n",
    "    # Store the coordinates in the city_coords dictionary\n",
    "    for city_name, coordinates in generator:\n",
    "        city_coords[city_name] = coordinates\n",
    "\n",
    "    cities = list(city_coords.keys())  # Get a list of city names\n",
    "\n",
    "    coords = np.array(list(city_coords.values()))  # Convert coordinates to a NumPy array\n",
    "    num_cities = len(cities)\n",
    "\n",
    "    # Calculate pairwise distances using cdist and geodesic\n",
    "    distances = cdist(coords, coords, lambda u, v: geodesic(u, v).kilometers)\n",
    "\n",
    "    # Create a DataFrame from the distances array for easier indexing\n",
    "    df_distances = pd.DataFrame(distances, index=cities, columns=cities)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    distance_matrix = df_distances.to_dict()\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "574c0e2a",
   "metadata": {},
   "source": [
    "distance_matrix = calculate_distance_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb7ef2",
   "metadata": {},
   "source": [
    "<u>the actual output of the distance matrix generator section</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329b04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# disable performance profiling for this section \n",
    "measure_time.enabled = False\n",
    "\n",
    "calculate_distance_matrix(\n",
    "    create_location_generator(citiesSample)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac332c",
   "metadata": {},
   "source": [
    "# distance matrix generator with frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998b474",
   "metadata": {},
   "source": [
    "## <u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933d994",
   "metadata": {},
   "source": [
    "L'objectif est de générer une matrice de distance prenant en compte la fréquentation. <br> Ainsi nous présenterons la fréquentation sous la forme d'un tableau contenant 4 valeurs (temps de trajets) indiqués à différents moments de la journée (les deux moitiés matin et après midi).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def generate_distances_frequency(distances):\n",
    "    distances_frequencies = {}\n",
    "\n",
    "    for city_a, times in distances.items():\n",
    "        distances_frequencies[city_a] = {}\n",
    "\n",
    "        for city_b, time in times.items():\n",
    "            if city_a == city_b:\n",
    "                distances_frequencies[city_a][city_b] = [0 for i in range(4)]  # Assuming no traffic within the same city\n",
    "            else:\n",
    "                distances_frequencies[city_a][city_b] = [np.random.uniform(1.0, 1.5) * time for i in range(4)]\n",
    "    \n",
    "    return distances_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_location_generator(citiesSample)\n",
    "generate_distances_frequency(calculate_distance_matrix(generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee7a74",
   "metadata": {},
   "source": [
    "## <u>optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c5b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9f3ca",
   "metadata": {},
   "source": [
    "# Initial solutions provider (no constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebcd6e9",
   "metadata": {},
   "source": [
    "## <u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c50c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_initial_solutions(distances,start_point):\n",
    "    points = list(distances.keys())\n",
    "    points.remove(start_point)\n",
    "    remaining_points = points[:]\n",
    "    path = [start_point]\n",
    "    while remaining_points:\n",
    "        next_point = np.random.choice(remaining_points)\n",
    "        path.append(next_point)\n",
    "        remaining_points.remove(next_point)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95eb0d",
   "metadata": {},
   "source": [
    "## <u>optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f37b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdbe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## <u>output</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_to_default_seed()\n",
    "\n",
    "generator = create_location_generator(citiesSample)\n",
    "distances_km = calculate_distance_matrix(generator)\n",
    "\n",
    "start = next(iter(distances_km))\n",
    "\n",
    "path = generate_random_initial_solutions(distances_km,start)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e87eb",
   "metadata": {},
   "source": [
    "# genetic algorithm with frequency constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable performance profiling for this section \n",
    "measure_time.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d627eb2",
   "metadata": {},
   "source": [
    "<u>non-optimized</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "def fitness(tour,distances,start_time): \n",
    "    current_time= start_time\n",
    "    current_distance = 0\n",
    "    for x in range(len(tour)-1):\n",
    "        if current_time > 1440:\n",
    "            current_time-=1440\n",
    "        current_distance += distances[tour[x]][tour[x+1]][current_time//360]\n",
    "    return current_distance\n",
    "\n",
    "# Sélection des parents par tournoi\n",
    "def selection_tournament(population,distances,start_time,tournament_size):\n",
    "    selected_parents = []\n",
    "    for _ in range(len(population)):\n",
    "        participants = random.sample(population, tournament_size)\n",
    "        winner = min(participants, key=lambda k: fitness(k, distances,start_time))\n",
    "        selected_parents.append(winner)\n",
    "    return selected_parents\n",
    "\n",
    "# Croisement de chad\n",
    "def crossover(parent1, parent2):\n",
    "    div = 3\n",
    "    liste_manquante = []\n",
    "    offspring = []\n",
    "    c1_part1 = parent1[0:int((len(parent1)) / div)]\n",
    "    c1_part2 = parent1[int((len(parent1)) / div):int(len(parent1) - int((len(parent1)) / div))]\n",
    "    c1_part3 = parent1[int(len(parent1) - int((len(parent1)) / div)):]\n",
    "    c2_part1 = parent2[0:int((len(parent2)) / div)]\n",
    "    c2_part2 = parent2[int((len(parent2)) / div):int(len(parent2) - int((len(parent2)) / div))]\n",
    "    c2_part3 = parent2[int(len(parent2) - int((len(parent2)) / div)):]\n",
    "    for i in range(0, len(c2_part3)):\n",
    "        if c2_part3[i] not in c1_part2:\n",
    "            liste_manquante.append(c2_part3[i])\n",
    "    for i in range(0, len(c2_part1)):\n",
    "        if c2_part1[i] not in c1_part2:\n",
    "            liste_manquante.append(c2_part1[i])\n",
    "    for i in range(0, len(c2_part2)):\n",
    "        if c2_part2[i] not in c1_part2:\n",
    "            liste_manquante.append(c2_part2[i])\n",
    "    for x in range(0, len(c1_part1)):\n",
    "        offspring.append(liste_manquante[x - len(c1_part3)])\n",
    "    offspring.extend(c1_part2)\n",
    "    for x in range(0, len(c1_part3)):\n",
    "        offspring.append(liste_manquante[x])\n",
    "    return offspring;\n",
    "\n",
    "# Opération 2-opt\n",
    "def two_opt(tour,distances_freq,start_time): #O(n^2)\n",
    "    improved = True\n",
    "    best_distance = fitness(tour,distances_freq,start_time)\n",
    "\n",
    "    while improved:\n",
    "        improved = False\n",
    "        for i in range(1, len(tour) - 1):\n",
    "            for j in range(i + 1, len(tour)):\n",
    "                new_tour = tour[:i] + tour[i:j][::-1] + tour[j:]\n",
    "                new_distance = fitness(new_tour,distances_freq,start_time)\n",
    "                if new_distance < best_distance:\n",
    "                    tour = new_tour\n",
    "                    best_distance = new_distance\n",
    "                    improved = True\n",
    "\n",
    "    return tour\n",
    "\n",
    "def mutate(tour,mutation_rate):\n",
    "    p = np.random.randint(0, 100)\n",
    "    if p < mutation_rate:\n",
    "        gene1 = np.random.randint(1, len(tour)-2)\n",
    "        gene2 = np.random.randint(1, len(tour)-2)\n",
    "        tour[gene1], tour[gene2] = tour[gene2], tour[gene1]\n",
    "    return tour;\n",
    "\n",
    "def select_parents(population, distances_freq,starttime,tournament_size):\n",
    "    fitness_sum = sum(fitness(individual,distances_freq,starttime) for individual in population)\n",
    "    probabilities = [fitness(individual,distances_freq,starttime) / fitness_sum for individual in population]\n",
    "    parents = random.choices(population, weights=probabilities, k=tournament_size)\n",
    "    return parents\n",
    "\n",
    "def fill_pop_with_random(population,range_for,start_point,distances):\n",
    "    for i in range(range_for):\n",
    "        population.append(generate_random_initial_solutions(distances, start_point))\n",
    "    return population\n",
    "\n",
    "# Algorithme génétique\n",
    "@measure_time\n",
    "def genetic_algorithm(distances_freq,population_size,num_generations,mutation_rate,tournament_size,start_point,starttime,children_size,elite_size):\n",
    "        \n",
    "    best_distance = 0 # O(1)\n",
    "    optimum_count = 0 # O(1)\n",
    "    \n",
    "    progress_bar = tqdm( # O(1)\n",
    "        total=num_generations, \n",
    "        desc=\"Genetic Algorithm\", \n",
    "        unit=\"generation\", \n",
    "    )\n",
    "    \n",
    "    # Initialisation de la population\n",
    "    population = fill_pop_with_random([],population_size,start_point,distances_freq)# O(n)\n",
    "    for gen in range(num_generations):\n",
    "        # Sélection des parents\n",
    "        parents = selection_tournament(population,distances_freq,starttime,tournament_size)# O(n * n)\n",
    "\n",
    "        parents = sorted(parents, key=lambda k: fitness(k, distances_freq,starttime))# O(n * log(n))\n",
    "        \n",
    "        #Ajout d'une élite à la population\n",
    "        population = [parents[0]] + random.sample(parents[:tournament_size],elite_size) # O(n)\n",
    "        offspring = []\n",
    "        for i in range(children_size):\n",
    "            parent1, parent2 = random.choice(parents[:tournament_size]),parents[i]# O(1)\n",
    "            child = crossover(parent1, parent2)# O(len(n))\n",
    "            child = mutate(child,mutation_rate)# O(len(n))\n",
    "            offspring.append(child)# O(1)\n",
    "            \n",
    "        # Remplacement de la population\n",
    "        population = population + offspring # O(len(n))\n",
    "        population = fill_pop_with_random(population,population_size-len(population),start_point,distances_freq)# O(n - len(n))\n",
    "            \n",
    "        currentwinner = min(population, key=lambda k: fitness(k, distances_freq,starttime))# O(n)\n",
    "        \n",
    "        best_distance = fitness(currentwinner, distances_freq,starttime)# O(len(n))\n",
    "        #print(\"Current winner with : \",best_distance)\n",
    "        #print(\"Current pop count : \",len(population))\n",
    "        #print(\"Current generation : \",gen)\n",
    "        #print(\"---------\")\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "\n",
    "    # Meilleure tournée après les générations\n",
    "    best_tour = min(population, key=lambda k: fitness(k, distances_freq,starttime))# O(n)\n",
    "    best_tour.append(best_tour[0])# O(1)\n",
    "    \n",
    "    #Optimisation finale\n",
    "    best_tour = two_opt(best_tour,distances_freq,starttime)#O(n)\n",
    "    \n",
    "    # Évaluation de la meilleure tournée\n",
    "    best_distance = fitness(best_tour,distances_freq,starttime)#O(len(n))\n",
    "\n",
    "    return best_tour, best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfdca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_location_generator(citiesSample)\n",
    "distances_freq = generate_distances_frequency(calculate_distance_matrix(generator))\n",
    "\n",
    "start_point = next(iter(distances_freq.keys())) # this represent the first town found in the distances dict \n",
    "# this represent the first town found in the distances dict \n",
    "\n",
    "path = genetic_algorithm(distances_freq,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94863b",
   "metadata": {},
   "source": [
    "<u>optimized</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168396e2",
   "metadata": {},
   "source": [
    "- The optimized version utilizes NumPy's vectorized operations to perform calculations on arrays of distances and boolean masks. These operations can be executed efficiently in parallel, leading to improved performance compared to the iterative approach in the non-optimized version.\n",
    "- The optimized version reduces the number of conditional checks by updating the nearest town and minimum distance within the vectorized operations. This avoids multiple checks and updates within the loop, resulting in faster execution.\n",
    "- The optimized version uses NumPy's array indexing functions (isin and argmin) to identify unvisited towns and find the index of the nearest town with the shortest distance. These indexing operations are optimized in NumPy and provide faster access and retrieval of elements from arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81a17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator = create_location_generator(citiesSample)\n",
    "distances_freq = generate_distances_frequency(calculate_distance_matrix(generator))\n",
    "\n",
    "start_point = next(iter(distances_freq.keys())) # this represent the first town found in the distances dict \n",
    "# this represent the first town found in the distances dict \n",
    "\n",
    "path = genetic_algorithm(distances_freq,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1fd1c",
   "metadata": {},
   "source": [
    "<u>the actual output of the genetic algorithm</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b30665",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_location_generator(citiesSample)\n",
    "distances_freq = generate_distances_frequency(calculate_distance_matrix(generator))\n",
    "\n",
    "start_point = next(iter(distances_freq.keys())) # this represent the first town found in the distances dict \n",
    "# this represent the first town found in the distances dict \n",
    "\n",
    "path = genetic_algorithm(distances_freq,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size)\n",
    "print(\"Path:\", ' -> '.join(path[0]))\n",
    "print(\"Time to travel :\",fitness(path[0],distances_freq,start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8c8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_cities(citiesSample, path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794caaf",
   "metadata": {},
   "source": [
    "# genetic algorithm with all constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991dba46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_into_trucks(time_matrix, num_trucks):\n",
    "    # Convert the time matrix to a numpy array\n",
    "    towns = list(time_matrix.keys())\n",
    "    time_array = np.array([[np.average(time_matrix[town1][town2]) for town2 in towns] for town1 in towns])\n",
    "    \n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_trucks, random_state=0, n_init=10).fit(time_array)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # Find the index of the first town in the time matrix\n",
    "    first_town_index = towns.index(towns[0])\n",
    "    \n",
    "    \n",
    "    # Create time matrices for each truck\n",
    "    trucks = []\n",
    "    for i in range(num_trucks):\n",
    "        # Filter towns based on the label or if it's the first town\n",
    "        truck_towns = [towns[j] for j in range(len(towns)) if labels[j] == i or j == first_town_index]\n",
    "        truck_time_matrix = {town: {truck_town: time_matrix[town][truck_town] for truck_town in truck_towns} for town in truck_towns}\n",
    "        trucks.append(truck_time_matrix)\n",
    "    \n",
    "    return trucks\n",
    "\n",
    "\n",
    "def fitness(tour,distances,start_time):\n",
    "    current_time= start_time\n",
    "    current_distance = 0\n",
    "    for x in range(len(tour)-1):\n",
    "        if current_time > 1440:\n",
    "            current_time-=1440\n",
    "        current_distance += distances[tour[x]][tour[x+1]][current_time//360]\n",
    "    return current_distance\n",
    "\n",
    "# Sélection des parents par tournoi\n",
    "def selection_tournament(population,distances,start_time,tournament_size):\n",
    "    selected_parents = []\n",
    "    for _ in range(len(population)):\n",
    "        participants = random.sample(population, tournament_size)\n",
    "        winner = min(participants, key=lambda k: fitness(k, distances,start_time))\n",
    "        selected_parents.append(winner)\n",
    "    return selected_parents\n",
    "\n",
    "# Croisement\n",
    "def crossover(parent1, parent2):\n",
    "    div = 3\n",
    "    offspring = [parent1[0]]  # Le premier élément de parent1 est ajouté à offspring\n",
    "    c1_part1 = parent1[0:int((len(parent1)) / div)]\n",
    "    c1_part2 = parent1[int((len(parent1)) / div):int(len(parent1) - int((len(parent1)) / div))]\n",
    "    c1_part3 = parent1[int(len(parent1) - int((len(parent1)) / div)):]\n",
    "    c2_part1 = parent2[0:int((len(parent2)) / div)]\n",
    "    c2_part2 = parent2[int((len(parent2)) / div):int(len(parent2) - int((len(parent2)) / div))]\n",
    "    c2_part3 = parent2[int(len(parent2) - int((len(parent2)) / div)):]\n",
    "    \n",
    "    for i in range(0, len(c2_part3)):\n",
    "        if c2_part3[i] not in c1_part2:\n",
    "            offspring.append(c2_part3[i])\n",
    "    for i in range(0, len(c2_part1)):\n",
    "        if c2_part1[i] not in c1_part2 and c2_part1[i] not in offspring:\n",
    "            offspring.append(c2_part1[i])\n",
    "    for i in range(0, len(c2_part2)):\n",
    "        if c2_part2[i] not in c1_part2 and c2_part2[i] not in offspring:\n",
    "            offspring.append(c2_part2[i])\n",
    "    \n",
    "    offspring.extend(c1_part2)\n",
    "    \n",
    "    for x in range(0, len(c1_part3)):\n",
    "        if c1_part3[x] not in offspring:\n",
    "            offspring.append(c1_part3[x])\n",
    "            \n",
    "    return offspring\n",
    "\n",
    "\n",
    "# Opération 2-opt\n",
    "def two_opt(tour,distances_freq,start_time):\n",
    "    improved = True\n",
    "    best_distance = fitness(tour,distances_freq,start_time)\n",
    "\n",
    "    while improved:\n",
    "        improved = False\n",
    "        for i in range(1, len(tour) - 1):\n",
    "            for j in range(i + 1, len(tour)):\n",
    "                new_tour = tour[:i] + tour[i:j][::-1] + tour[j:]\n",
    "                new_distance = fitness(new_tour,distances_freq,start_time)\n",
    "                if new_distance < best_distance:\n",
    "                    tour = new_tour\n",
    "                    best_distance = new_distance\n",
    "                    improved = True\n",
    "\n",
    "    return tour\n",
    "\n",
    "def mutate(tour,mutation_rate):\n",
    "    p = random.randint(0, 100)\n",
    "    if p < mutation_rate:\n",
    "        gene1 = random.randint(1, len(tour)-2)\n",
    "        gene2 = random.randint(1, len(tour)-2)\n",
    "        tour[gene1], tour[gene2] = tour[gene2], tour[gene1]\n",
    "    return tour;\n",
    "\n",
    "def select_parents(population, distances_freq,starttime,tournament_size):\n",
    "    fitness_sum = sum(fitness(individual,distances_freq,starttime) for individual in population)\n",
    "    probabilities = [fitness(individual,distances_freq,starttime) / fitness_sum for individual in population]\n",
    "    parents = random.choices(population, weights=probabilities, k=tournament_size)\n",
    "    return parents\n",
    "\n",
    "def fill_pop_with_random(population,range_for,start_point,distances):\n",
    "    for i in range(range_for):\n",
    "        population.append(generate_random_initial_solutions(distances, start_point))\n",
    "    return population\n",
    "\n",
    "def filter_cities_by_truck(citiesSample, truck):\n",
    "    town_list = list(truck.keys())\n",
    "    filtered_cities = [city for city in citiesSample if city[4] in town_list]\n",
    "    return np.array(filtered_cities)\n",
    "\n",
    "# Algorithme génétique\n",
    "@measure_time\n",
    "def genetic_algorithm(distances_freq,population_size,num_generations,mutation_rate,tournament_size,start_point,starttime,children_size,elite_size):\n",
    "    \n",
    "    best_distance = 0  # O(1)\n",
    "    optimum_count = 0   # O(1)\n",
    "    \n",
    "    progress_bar = tqdm(\n",
    "        total=num_generations, \n",
    "        desc=\"Genetic Algorithm\", \n",
    "        unit=\"generation\", \n",
    "    )\n",
    "    # Initialisation de la population\n",
    "    population = fill_pop_with_random([],population_size,start_point,distances_freq)  # O(n)\n",
    "    for gen in range(num_generations):\n",
    "        # Sélection des parents\n",
    "        parents = selection_tournament(population,distances_freq,starttime,tournament_size)  # O(n*n)\n",
    "\n",
    "        parents = sorted(parents, key=lambda k: fitness(k, distances_freq,starttime))  # O(n * log(n))\n",
    "        \n",
    "        #Ajout d'une élite à la population\n",
    "        population = [parents[0]] + random.sample(parents[:tournament_size],elite_size)  # O(n)\n",
    "        offspring = []\n",
    "        for i in range(children_size):\n",
    "            parent1, parent2 = random.choice(parents[:tournament_size]),parents[i]  # O(1)\n",
    "            child = crossover(parent1, parent2)  # O(len(n))\n",
    "            child = mutate(child,mutation_rate)  # O(len(n))\n",
    "            offspring.append(child)  # O(1)\n",
    "        # Remplacement de la population\n",
    "        population = population + offspring\n",
    "        population = fill_pop_with_random(population,population_size-len(population),start_point,distances_freq)\n",
    "            \n",
    "        currentwinner = min(population, key=lambda k: fitness(k, distances_freq,starttime))\n",
    "        \n",
    "        best_distance = fitness(currentwinner, distances_freq,starttime)\n",
    "        #print(\"Current winner with : \",best_distance)\n",
    "        #print(\"Current pop count : \",len(population))\n",
    "        #print(\"Current generation : \",gen)\n",
    "        #print(\"---------\")\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "\n",
    "    # Meilleure tournée après les générations\n",
    "    best_tour = min(population, key=lambda k: fitness(k, distances_freq,starttime))  # O(n)\n",
    "    best_tour.append(best_tour[0])  # O(1)\n",
    "    \n",
    "    #Optimisation finale\n",
    "    best_tour = two_opt(best_tour,distances_freq,starttime)# O(n^2)\n",
    "    \n",
    "    # Évaluation de la meilleure tournée\n",
    "    best_distance = fitness(best_tour,distances_freq,starttime)# O(len(n))\n",
    "\n",
    "\n",
    "    return best_tour, best_distance\n",
    "\n",
    "def optimize_trucks(map_obj,citiesSample,trucks,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size, use_traffic_matrix=False):\n",
    "    routes = []\n",
    "    for i, truck in enumerate(trucks):\n",
    "        if use_traffic_matrix:\n",
    "            truck = generate_traffic_matrix(truck)\n",
    "        best_route, best_time = genetic_algorithm(truck,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size)\n",
    "        \n",
    "        print(f\"The truck n: {i} will do: {best_route} for a total of {best_time} h\")\n",
    "        plot_cities(filter_cities_by_truck(citiesSample, truck), best_route, map_obj=map_obj, color=color[i])\n",
    "        routes.append([best_route, best_time])\n",
    "    return map_obj, routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c00da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = [float(citiesSample[0][2]), float(citiesSample[0][3])]\n",
    "map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "\n",
    "generator = create_location_generator(citiesSample)\n",
    "distances_km = calculate_distance_matrix(generator)\n",
    "distances_freqU = generate_distances_frequency(distances_km)\n",
    "trucks = split_into_trucks(distances_freqU,truck_number)\n",
    "\n",
    "start_point = next(iter(distances_km.keys())) # this represent the first town found in the distances dict \n",
    "# this represent the first town found in the distances dict \n",
    "\n",
    "print(start_point)\n",
    "\n",
    "map_obj,routes = optimize_trucks(map_obj,citiesSample,trucks,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size)\n",
    "\n",
    "map_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0effa9ed",
   "metadata": {},
   "source": [
    "# Upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0948b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa822ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def solve_issue(trucks):\n",
    "    max_value = 0\n",
    "    # solve with pulp\n",
    "    for initial_truck in trucks:\n",
    "        truck = {}\n",
    "        for element in initial_truck:\n",
    "            truck[element] = {}\n",
    "            for subelement in initial_truck[element]:\n",
    "                truck[element][subelement] = np.round(initial_truck[element][subelement])\n",
    "            \n",
    "        # definition of LpProblem instance\n",
    "        problem =pulp.LpProblem(\"CVRP\", pulp.LpMinimize)\n",
    "\n",
    "        truck_keys = list(truck.keys())\n",
    "        \n",
    "        # definition of variables \n",
    "        x = [[[pulp.LpVariable(\"x%s_%s\"%(i,j), cat=\"Binary\") if i != j else None] for j in truck_keys] for i in truck_keys]\n",
    "        print(x)\n",
    "        \n",
    "        # add objective function\n",
    "        problem += pulp.lpSum(np.min(truck[ikey][jkey]).astype(int) * x[iindex][jindex] if iindex != jindex else 0\n",
    "                              for jindex,jkey in enumerate(truck_keys)\n",
    "                              for iindex,ikey in enumerate(truck_keys))\n",
    "\n",
    "        \n",
    "        # constraints\n",
    "        for j in range(1, len(truck)):\n",
    "            problem += pulp.lpSum(x[iindex][j] if iindex != j else 0 \n",
    "                                  for iindex,ikey in enumerate(truck_keys)) == 1 \n",
    "        \n",
    "        problem += pulp.lpSum(x[0][iindex] for iindex,ikey in enumerate(truck_keys)) == 1\n",
    "        problem += pulp.lpSum(x[jindex][0] for jindex,jkey in enumerate(truck_keys)) == 1\n",
    "        \n",
    "        subtours = []\n",
    "        for i in range(2,len(truck)):\n",
    "             subtours += itertools.combinations(range(1,len(truck)), i)\n",
    "\n",
    "        for s in subtours:\n",
    "            problem += pulp.lpSum(x[i][j] if i !=j else 0 for i, j in itertools.permutations(s,2)) <= len(s) - 1\n",
    "\n",
    "        \n",
    "        problem.solve()\n",
    "        print(pulp.value(problem.objective))\n",
    "        if pulp.LpStatus[problem.status] == \"Optimal\":\n",
    "            if(max_value < pulp.value(problem.objective)):\n",
    "                max_value = pulp.value(problem.objective)\n",
    "                print(\"NEW STRONK\")\n",
    "        else:\n",
    "            raise Exception(\"No optimal solution found.\")\n",
    "\n",
    "    return max_value\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a99a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_location_generator(citiesSample)\n",
    "distances_km = calculate_distance_matrix(generator)\n",
    "distances_freq = generate_distances_frequency(distances_km)\n",
    "trucks = split_into_trucks(distances_freq,truck_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_issue(trucks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357b8a1",
   "metadata": {},
   "source": [
    "# genetic algorithm with all constraints and multistart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22020e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multistart(num_iteration,citiesSample,trucks,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size):\n",
    "    current_best_distance = float('inf')\n",
    "    current_best_path = None\n",
    "    for i in range(num_iteration):\n",
    "        map_center = [float(citiesSample[0][2]), float(citiesSample[0][3])]\n",
    "        map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "        map_obj, paths = optimize_trucks(map_obj,citiesSample,trucks,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size)\n",
    "        \n",
    "        second_column = [sublist[1] for sublist in paths]\n",
    "        max_value = np.max(np.array(second_column))\n",
    "        \n",
    "        current_path_distance = max_value\n",
    "        \n",
    "        if current_best_distance > current_path_distance:\n",
    "            current_best_distance = current_path_distance\n",
    "            current_best_path = map_obj\n",
    "    return current_best_distance, current_best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = [float(citiesSample[0][2]), float(citiesSample[0][3])]\n",
    "map_obj = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "generator = create_location_generator(citiesSample)\n",
    "distances_km = calculate_distance_matrix(generator)\n",
    "distances_freq = generate_distances_frequency(distances_km)\n",
    "trucks = split_into_trucks(distances_freq,truck_number)\n",
    "\n",
    "start_point = next(iter(distances_km.keys())) # this represent the first town found in the distances dict \n",
    "# this represent the first town found in the distances dict \n",
    "\n",
    "print(start_point)\n",
    "\n",
    "size,map_obj = multistart(num_iteration,citiesSample,trucks,population_size,num_generations,mutation_rate,tournament_size,start_point,start_time,children_size,elite_size)\n",
    "\n",
    "print(\"With a maximum individual path size of :\",size)\n",
    "map_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9daf13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
